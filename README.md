# Project Board link

https://github.com/users/kamalm3/projects/2

---

## Project AI Rag solution architecture

The Retrieval-Augmented Generation (RAG) architecture merges the extensive knowledge of Large Language Models (LLMs) with precise document retrieval methods. This system starts with a user query and enhances response accuracy by first searching for relevant documents before generating an answer. Instead of relying solely on pre-trained data, RAG retrieves specific information from a custom dataset. The key to this process is vector search, which captures the semantic meaning of text rather than just matching keywords. It converts documents and queries into vectors and finds the closest matches based on context. Once relevant documents are retrieved, they are combined with the userâ€™s query to create a context-rich prompt. The LLM then uses this prompt to generate a detailed, informed response, delivering outputs that are both contextually accurate and coherent. This approach is especially effective for specialized or complex queries where up-to-date or niche information is crucial.

![rag architecture image](https://res.cloudinary.com/di0onpbp0/image/upload/v1724764692/rag_arch_lady5t.jpg)
